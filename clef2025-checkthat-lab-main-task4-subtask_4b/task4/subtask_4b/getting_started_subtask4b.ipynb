{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-29T21:29:16.313174Z",
          "start_time": "2025-05-29T21:29:16.297475Z"
        },
        "id": "ju-O-_37BW5m"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pSz8Re3C0AP"
      },
      "outputs": [],
      "source": [
        "#!ls \"/content/drive/My Drive/clef2025-checkthat-lab-main-task4-subtask_4b/task4/subtask_4b\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVAjelnVBtBv"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# project_path = \"/content/drive/My Drive/clef2025-checkthat-lab-main-task4-subtask_4b/task4/subtask_4b\"\n",
        "# os.chdir(project_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfnQvGfvtH1w"
      },
      "source": [
        "# Getting started\n",
        "\n",
        "### CLEF 2025 - CheckThat! Lab  - Task 4 Scientific Web Discourse - Subtask 4b (Scientific Claim Source Retrieval)\n",
        "\n",
        "This notebook enables participants of subtask 4b to quickly get started. It includes the following:\n",
        "- Code to upload data, including:\n",
        "    - code to upload the collection set (CORD-19 academic papers' metadata)\n",
        "    - code to upload the query set (tweets with implicit references to CORD-19 papers)\n",
        "- Code to run a baseline retrieval model (BM25)\n",
        "- Code to evaluate the baseline model\n",
        "\n",
        "Participants are free to use this notebook and add their own models for the competition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpDCfBMouNAL"
      },
      "source": [
        "# 1) Importing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rQPqDKP_QHFM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8N7h9BhQI5m"
      },
      "source": [
        "## 1.a) Import the collection set\n",
        "The collection set contains metadata of CORD-19 academic papers.\n",
        "\n",
        "The preprocessed and filtered CORD-19 dataset is available on the Gitlab repository here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
        "\n",
        "Participants should first download the file then upload it on the Google Colab session with the following steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2GQI4HcKR6hS"
      },
      "outputs": [],
      "source": [
        "# 1) Download the collection set from the Gitlab repository: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
        "# 2) Drag and drop the downloaded file to the \"Files\" section (left vertical menu on Colab)\n",
        "# 3) Modify the path to your local file path\n",
        "PATH_COLLECTION_DATA = 'subtask4b_collection_data.pkl' #MODIFY PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SYBB3UYbMwTA"
      },
      "outputs": [],
      "source": [
        "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v3lygNOQQSn",
        "outputId": "f3c4c57a-8678-4ebd-e94d-61cda99ecbe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 7718 entries, 162 to 1056448\n",
            "Data columns (total 17 columns):\n",
            " #   Column            Non-Null Count  Dtype         \n",
            "---  ------            --------------  -----         \n",
            " 0   cord_uid          7718 non-null   object        \n",
            " 1   source_x          7718 non-null   object        \n",
            " 2   title             7718 non-null   object        \n",
            " 3   doi               7677 non-null   object        \n",
            " 4   pmcid             4959 non-null   object        \n",
            " 5   pubmed_id         6233 non-null   object        \n",
            " 6   license           7718 non-null   object        \n",
            " 7   abstract          7718 non-null   object        \n",
            " 8   publish_time      7715 non-null   object        \n",
            " 9   authors           7674 non-null   object        \n",
            " 10  journal           6668 non-null   object        \n",
            " 11  mag_id            0 non-null      float64       \n",
            " 12  who_covidence_id  528 non-null    object        \n",
            " 13  arxiv_id          20 non-null     object        \n",
            " 14  label             7718 non-null   object        \n",
            " 15  time              7715 non-null   datetime64[ns]\n",
            " 16  timet             7718 non-null   int64         \n",
            "dtypes: datetime64[ns](1), float64(1), int64(1), object(14)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df_collection.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "9veNFFGDZRx7",
        "outputId": "b10691f3-2bb3-4284-b61b-2f92b038a9c5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cord_uid</th>\n",
              "      <th>source_x</th>\n",
              "      <th>title</th>\n",
              "      <th>doi</th>\n",
              "      <th>pmcid</th>\n",
              "      <th>pubmed_id</th>\n",
              "      <th>license</th>\n",
              "      <th>abstract</th>\n",
              "      <th>publish_time</th>\n",
              "      <th>authors</th>\n",
              "      <th>journal</th>\n",
              "      <th>mag_id</th>\n",
              "      <th>who_covidence_id</th>\n",
              "      <th>arxiv_id</th>\n",
              "      <th>label</th>\n",
              "      <th>time</th>\n",
              "      <th>timet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>umvrwgaw</td>\n",
              "      <td>PMC</td>\n",
              "      <td>Professional and Home-Made Face Masks Reduce E...</td>\n",
              "      <td>10.1371/journal.pone.0002618</td>\n",
              "      <td>PMC2440799</td>\n",
              "      <td>18612429</td>\n",
              "      <td>cc-by</td>\n",
              "      <td>BACKGROUND: Governments are preparing for a po...</td>\n",
              "      <td>2008-07-09</td>\n",
              "      <td>van der Sande, Marianne; Teunis, Peter; Sabel,...</td>\n",
              "      <td>PLoS One</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>umvrwgaw</td>\n",
              "      <td>2008-07-09</td>\n",
              "      <td>1215561600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>spiud6ok</td>\n",
              "      <td>PMC</td>\n",
              "      <td>The Failure of R (0)</td>\n",
              "      <td>10.1155/2011/527610</td>\n",
              "      <td>PMC3157160</td>\n",
              "      <td>21860658</td>\n",
              "      <td>cc-by</td>\n",
              "      <td>The basic reproductive ratio, R (0), is one of...</td>\n",
              "      <td>2011-08-16</td>\n",
              "      <td>Li, Jing; Blakeley, Daniel; Smith?, Robert J.</td>\n",
              "      <td>Comput Math Methods Med</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>spiud6ok</td>\n",
              "      <td>2011-08-16</td>\n",
              "      <td>1313452800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>918</th>\n",
              "      <td>aclzp3iy</td>\n",
              "      <td>PMC</td>\n",
              "      <td>Pulmonary sequelae in a patient recovered from...</td>\n",
              "      <td>10.4103/0970-2113.99118</td>\n",
              "      <td>PMC3424870</td>\n",
              "      <td>22919170</td>\n",
              "      <td>cc-by-nc-sa</td>\n",
              "      <td>The pandemic of swine flu (H1N1) influenza spr...</td>\n",
              "      <td>2012</td>\n",
              "      <td>Singh, Virendra; Sharma, Bharat Bhushan; Patel...</td>\n",
              "      <td>Lung India</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aclzp3iy</td>\n",
              "      <td>2012-01-01</td>\n",
              "      <td>1325376000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>ycxyn2a2</td>\n",
              "      <td>PMC</td>\n",
              "      <td>What was the primary mode of smallpox transmis...</td>\n",
              "      <td>10.3389/fcimb.2012.00150</td>\n",
              "      <td>PMC3509329</td>\n",
              "      <td>23226686</td>\n",
              "      <td>cc-by</td>\n",
              "      <td>The mode of infection transmission has profoun...</td>\n",
              "      <td>2012-11-29</td>\n",
              "      <td>Milton, Donald K.</td>\n",
              "      <td>Front Cell Infect Microbiol</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ycxyn2a2</td>\n",
              "      <td>2012-11-29</td>\n",
              "      <td>1354147200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1053</th>\n",
              "      <td>zxe95qy9</td>\n",
              "      <td>PMC</td>\n",
              "      <td>Lessons from the History of Quarantine, from P...</td>\n",
              "      <td>10.3201/eid1902.120312</td>\n",
              "      <td>PMC3559034</td>\n",
              "      <td>23343512</td>\n",
              "      <td>no-cc</td>\n",
              "      <td>In the new millennium, the centuries-old strat...</td>\n",
              "      <td>2013-02-03</td>\n",
              "      <td>Tognotti, Eugenia</td>\n",
              "      <td>Emerg Infect Dis</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>zxe95qy9</td>\n",
              "      <td>2013-02-03</td>\n",
              "      <td>1359849600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      cord_uid source_x                                              title  \\\n",
              "162   umvrwgaw      PMC  Professional and Home-Made Face Masks Reduce E...   \n",
              "611   spiud6ok      PMC                               The Failure of R (0)   \n",
              "918   aclzp3iy      PMC  Pulmonary sequelae in a patient recovered from...   \n",
              "993   ycxyn2a2      PMC  What was the primary mode of smallpox transmis...   \n",
              "1053  zxe95qy9      PMC  Lessons from the History of Quarantine, from P...   \n",
              "\n",
              "                               doi       pmcid pubmed_id      license  \\\n",
              "162   10.1371/journal.pone.0002618  PMC2440799  18612429        cc-by   \n",
              "611            10.1155/2011/527610  PMC3157160  21860658        cc-by   \n",
              "918        10.4103/0970-2113.99118  PMC3424870  22919170  cc-by-nc-sa   \n",
              "993       10.3389/fcimb.2012.00150  PMC3509329  23226686        cc-by   \n",
              "1053        10.3201/eid1902.120312  PMC3559034  23343512        no-cc   \n",
              "\n",
              "                                               abstract publish_time  \\\n",
              "162   BACKGROUND: Governments are preparing for a po...   2008-07-09   \n",
              "611   The basic reproductive ratio, R (0), is one of...   2011-08-16   \n",
              "918   The pandemic of swine flu (H1N1) influenza spr...         2012   \n",
              "993   The mode of infection transmission has profoun...   2012-11-29   \n",
              "1053  In the new millennium, the centuries-old strat...   2013-02-03   \n",
              "\n",
              "                                                authors  \\\n",
              "162   van der Sande, Marianne; Teunis, Peter; Sabel,...   \n",
              "611       Li, Jing; Blakeley, Daniel; Smith?, Robert J.   \n",
              "918   Singh, Virendra; Sharma, Bharat Bhushan; Patel...   \n",
              "993                                   Milton, Donald K.   \n",
              "1053                                  Tognotti, Eugenia   \n",
              "\n",
              "                          journal  mag_id who_covidence_id arxiv_id     label  \\\n",
              "162                      PLoS One     NaN              NaN      NaN  umvrwgaw   \n",
              "611       Comput Math Methods Med     NaN              NaN      NaN  spiud6ok   \n",
              "918                    Lung India     NaN              NaN      NaN  aclzp3iy   \n",
              "993   Front Cell Infect Microbiol     NaN              NaN      NaN  ycxyn2a2   \n",
              "1053             Emerg Infect Dis     NaN              NaN      NaN  zxe95qy9   \n",
              "\n",
              "           time       timet  \n",
              "162  2008-07-09  1215561600  \n",
              "611  2011-08-16  1313452800  \n",
              "918  2012-01-01  1325376000  \n",
              "993  2012-11-29  1354147200  \n",
              "1053 2013-02-03  1359849600  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_collection.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAUiDU0xXLBt"
      },
      "source": [
        "## 1.b) Import the query set\n",
        "\n",
        "The query set contains tweets with implicit references to academic papers from the collection set.\n",
        "\n",
        "The preprocessed query set is available on the Gitlab repository here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
        "\n",
        "Participants should first download the file then upload it on the Google Colab session with the following steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v8gwkZDSXPsd"
      },
      "outputs": [],
      "source": [
        "# 1) Download the query tweets from the Gitlab repository: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b?ref_type=heads\n",
        "# 2) Drag and drop the downloaded file to the \"Files\" section (left vertical menu on Colab)\n",
        "# 3) Modify the path to your local file path\n",
        "PATH_QUERY_TRAIN_DATA = 'subtask4b_query_tweets_train.tsv' #MODIFY PATH\n",
        "PATH_QUERY_DEV_DATA = 'subtask4b_query_tweets_dev.tsv' #MODIFY PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VqxjYq2tYDmE"
      },
      "outputs": [],
      "source": [
        "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
        "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "szMEK3OkYLvX",
        "outputId": "cdf30d12-3f1f-4303-f521-954b2d8493b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>cord_uid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
              "      <td>htlvpvz5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>this study isn't receiving sufficient attentio...</td>\n",
              "      <td>4kfl29ul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>thanks, xi jinping. a reminder that this study...</td>\n",
              "      <td>jtwb17u8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Taiwan - a population of 23 million has had ju...</td>\n",
              "      <td>0w9k8iy1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Obtaining a diagnosis of autism in lower incom...</td>\n",
              "      <td>tiqksd69</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   post_id                                         tweet_text  cord_uid\n",
              "0        0  Oral care in rehabilitation medicine: oral vul...  htlvpvz5\n",
              "1        1  this study isn't receiving sufficient attentio...  4kfl29ul\n",
              "2        2  thanks, xi jinping. a reminder that this study...  jtwb17u8\n",
              "3        3  Taiwan - a population of 23 million has had ju...  0w9k8iy1\n",
              "4        4  Obtaining a diagnosis of autism in lower incom...  tiqksd69"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_query_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aslmTTJQyL2X",
        "outputId": "6a82cb9d-85b5-4482-8e84-9c930c698fa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12853 entries, 0 to 12852\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   post_id     12853 non-null  int64 \n",
            " 1   tweet_text  12853 non-null  object\n",
            " 2   cord_uid    12853 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 301.4+ KB\n"
          ]
        }
      ],
      "source": [
        "df_query_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B5X8FwLhLY3u",
        "outputId": "321494ec-400e-447a-da71-69bae3bcef8a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>cord_uid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16</td>\n",
              "      <td>covid recovery: this study from the usa reveal...</td>\n",
              "      <td>3qvh482o</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
              "      <td>r58aohnu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>73</td>\n",
              "      <td>I recall early on reading that researchers who...</td>\n",
              "      <td>sts48u9i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>93</td>\n",
              "      <td>You know you're credible when NIH website has ...</td>\n",
              "      <td>3sr2exq9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>96</td>\n",
              "      <td>Resistance to antifungal medications is a grow...</td>\n",
              "      <td>ybwwmyqy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   post_id                                         tweet_text  cord_uid\n",
              "0       16  covid recovery: this study from the usa reveal...  3qvh482o\n",
              "1       69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu\n",
              "2       73  I recall early on reading that researchers who...  sts48u9i\n",
              "3       93  You know you're credible when NIH website has ...  3sr2exq9\n",
              "4       96  Resistance to antifungal medications is a grow...  ybwwmyqy"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_query_dev.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6gDlBZnLcdH",
        "outputId": "6368a5e3-e31e-48e2-8fa8-329bc50e6f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1400 entries, 0 to 1399\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   post_id     1400 non-null   int64 \n",
            " 1   tweet_text  1400 non-null   object\n",
            " 2   cord_uid    1400 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 32.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df_query_dev.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr_BDzufPmmP"
      },
      "source": [
        "# 2) Running the baseline\n",
        "The following code runs a BM25 baseline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHfJ7ItxO8u8",
        "outputId": "5965d775-f87c-4d1c-9cda-23b7bd6d342a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "Requirement already satisfied: rank_bm25 in /opt/conda/lib/python3.11/site-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from rank_bm25) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install rank_bm25\n",
        "from rank_bm25 import BM25Okapi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xQ2x8Gt0_4p"
      },
      "source": [
        "To build a BM25-based search engine that allows you to **score papers based on a tweet query**, using **text similarity** (word matching).\n",
        "* Combine title and abstract into one text field for each paper\n",
        "* Creates a list of paper IDs in the same order as the corpus. These IDs help you **track which paper each text belongs to**\n",
        "* Splits each combined `title + abstract` into words (tokens)\n",
        "* bm25 = BM25Okapi(tokenized_corpus): Creates the actual **BM25 model** using your list of tokenized documents. BM25 now knows which papers contain which words, and how important those words are"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXCC7K_ZPQL2"
      },
      "outputs": [],
      "source": [
        "# Create the BM25 corpus\n",
        "corpus = df_collection[:][['title', 'abstract']].apply(lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
        "cord_uids = df_collection[:]['cord_uid'].tolist()\n",
        "tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK0gFcNH0_4p"
      },
      "source": [
        "This function is the **retrieval step** of your traditional IR model — it takes a tweet and returns the **top-5 paper IDs** that are most relevant based on BM25 scores.\n",
        "* You give it a `query` (the tweet text). It returns a list of the **top 5 paper IDs (`cord_uid`)** that best match the query, based on BM25.\n",
        "* Initializes a **temporary cache dictionary**\n",
        "* Checks if this query has already been processed and cached.\n",
        "* Tokenizes the tweet into words (BM25 needs tokens, not raw strings).\n",
        "  * For example: `\"masks help prevent spread\"` → `[\"masks\", \"help\", \"prevent\", \"spread\"]`\n",
        "* Scores each paper in the BM25 corpus by how well it matches the query tokens. Returns a list of scores (one per paper).\n",
        "* Sorts the scores **in descending order**\n",
        "* Looks up the **cord\\_uid (paper ID)** of those top 5 indices.\n",
        "* Saves the result to the cache (though it gets wiped every call unless you fix it). Returns the top 5 paper IDs for this query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8NeJWGYPQZG"
      },
      "outputs": [],
      "source": [
        "def get_top_cord_uids(query):\n",
        "  text2bm25top = {}\n",
        "  if query in text2bm25top.keys():\n",
        "      return text2bm25top[query]\n",
        "  else:\n",
        "      tokenized_query = query.split(' ')\n",
        "      doc_scores = bm25.get_scores(tokenized_query)\n",
        "      indices = np.argsort(-doc_scores)[:5]\n",
        "      bm25_topk = [cord_uids[x] for x in indices]\n",
        "\n",
        "      text2bm25top[query] = bm25_topk\n",
        "      return bm25_topk\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfNokhCc0_4q"
      },
      "source": [
        "This part of the code is where you actually **use the BM25 retrieval model** on your training and dev datasets.\n",
        "You're applying the `get_top_cord_uids()` function (the BM25 search function) to every tweet in your training and development sets.\n",
        "* Takes each tweet in the `tweet_text` column of `df_query_train`\n",
        "* Passes it to your `get_top_cord_uids()` function\n",
        "* That function uses **BM25** to retrieve the **top-5 most relevant paper IDs**\n",
        "* Saves the list of top 5 `cord_uid`s to a new column called `bm25_topk`\n",
        "You then do the same for the dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk4-BqEtTgUj"
      },
      "outputs": [],
      "source": [
        "# Retrieve topk candidates using the BM25 model\n",
        "df_query_train['bm25_topk'] = df_query_train['tweet_text'].apply(lambda x: get_top_cord_uids(x))\n",
        "df_query_dev['bm25_topk'] = df_query_dev['tweet_text'].apply(lambda x: get_top_cord_uids(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVKBlTCZUMSc"
      },
      "source": [
        "# 3) Evaluating the baseline\n",
        "The following code evaluates the BM25 retrieval baseline on the query set using the Mean Reciprocal Rank score (MRR@5)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IADp3rjf0_4q"
      },
      "source": [
        "Calculate **how well your model is ranking the correct paper**, based on different top-k cutoffs (like top-1, top-5, and top-10).\n",
        "* **At what position** the correct `cord_uid` appears in your model’s predictions.\n",
        "* And returns the **average of reciprocal ranks** over all queries.\n",
        "* `col_gold`: The column containing the correct paper ID (usually `'cord_uid'`)\n",
        "* `col_pred`: The column containing a list of predicted paper IDs (e.g. `'bm25_topk'` or `'reranked_topk'`)\n",
        "* `list_k`: The cutoffs you want to compute MRR\\@k for (e.g. `[1, 5, 10]`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c-vdGWXXTgjZ"
      },
      "outputs": [],
      "source": [
        "# Evaluate retrieved candidates using MRR@k\n",
        "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
        "    d_performance = {}\n",
        "    for k in list_k:\n",
        "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
        "        #performances.append(data[\"in_topx\"].mean())\n",
        "        d_performance[k] = data[\"in_topx\"].mean()\n",
        "    return d_performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW8wI22E0_4r"
      },
      "source": [
        "This block of code is **evaluating how well your BM25 retrieval performed** using the `get_performance_mrr()` function you defined earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLX9SMg5USkH",
        "outputId": "f351c36a-816d-41cb-b255-b8354431ed25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the train set: {1: 0.5080525947249669, 5: 0.5509388210275163, 10: 0.5509388210275163}\n",
            "Results on the dev set: {1: 0.505, 5: 0.5520357142857142, 10: 0.5520357142857142}\n"
          ]
        }
      ],
      "source": [
        "results_train = get_performance_mrr(df_query_train, 'cord_uid', 'bm25_topk')\n",
        "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'bm25_topk')\n",
        "# Printed MRR@k results in the following format: {k: MRR@k}\n",
        "print(f\"Results on the train set: {results_train}\")\n",
        "print(f\"Results on the dev set: {results_dev}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RazcRTV84KQC"
      },
      "source": [
        "# 4) Exporting results to prepare the submission on Codalab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFng4ocDw3Hk"
      },
      "outputs": [],
      "source": [
        "#df_query_dev['preds'] = df_query_dev['bm25_topk'].apply(lambda x: x[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAVBQYh_xP8O"
      },
      "outputs": [],
      "source": [
        "#df_query_dev[['post_id', 'preds']].to_csv('predictions.tsv', index=None, sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFd4svOhXEgI"
      },
      "source": [
        "# **Part 1: Traditional IR Model (BM25)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLXW2sLvMrim",
        "outputId": "fe39289d-ef34-4a1d-c11b-b6aa04c0869e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRR@5 (local test split): 0.5460\n"
          ]
        }
      ],
      "source": [
        "#New version, had to adjust due to missing the CLEF deadline.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# 1. Combine and clean training + dev queries\n",
        "df_query_train[\"split_origin\"] = \"train\"\n",
        "df_query_dev[\"split_origin\"] = \"dev\"\n",
        "df_all_queries = pd.concat([df_query_train, df_query_dev], ignore_index=True)\n",
        "df_all_queries = df_all_queries.drop_duplicates(subset=[\"tweet_text\"])\n",
        "\n",
        "# 2. Split into new train/test sets (80/20)\n",
        "df_train_split, df_test_split = train_test_split(\n",
        "    df_all_queries, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Build BM25 index on document collection\n",
        "df_collection['combined_text'] = (df_collection['title'] + ' ' + df_collection['abstract']).fillna('')\n",
        "corpus = df_collection['combined_text'].apply(word_tokenize).tolist()\n",
        "bm25 = BM25Okapi(corpus)\n",
        "\n",
        "# 4. Define BM25 retrieval function\n",
        "def get_top_cord_uids(query, topk=20):\n",
        "    tokenized_query = word_tokenize(query)\n",
        "    scores = bm25.get_scores(tokenized_query)\n",
        "    top_indices = scores.argsort()[-topk:][::-1]\n",
        "    return df_collection.iloc[top_indices]['cord_uid'].tolist()\n",
        "\n",
        "# 5. Run BM25 on test set\n",
        "df_test_split['bm25_topk'] = df_test_split['tweet_text'].apply(lambda x: get_top_cord_uids(x))\n",
        "\n",
        "# 6. Evaluate MRR@5 using your own function\n",
        "def mrr_at_5(df):\n",
        "    reciprocal_ranks = []\n",
        "    for _, row in df.iterrows():\n",
        "        true_uid = row['cord_uid']\n",
        "        preds = row['bm25_topk'][:5]\n",
        "        if true_uid in preds:\n",
        "            rank = preds.index(true_uid) + 1\n",
        "            reciprocal_ranks.append(1 / rank)\n",
        "        else:\n",
        "            reciprocal_ranks.append(0)\n",
        "    return sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
        "\n",
        "score = mrr_at_5(df_test_split)\n",
        "print(f'MRR@5 (local test split): {score:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TinZY-6j0_42"
      },
      "outputs": [],
      "source": [
        "#df_query_dev.bm25_topk[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygzzs5YeWfrv"
      },
      "source": [
        "# **Part 2: Neural IR Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XM8MMarAa8_m"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Dict\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_texts(model: SentenceTransformer, texts: List[str], batch_size: int = 32):\n",
        "    return model.encode(texts, convert_to_tensor=True, show_progress_bar=True, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "FOB_1KuD2QJq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_top_k(query_embeddings, doc_embeddings, doc_ids, top_k=10) -> List[List[str]]:\n",
        "    all_preds = []\n",
        "    for query_embedding in query_embeddings:\n",
        "        scores = util.cos_sim(query_embedding, doc_embeddings)[0]\n",
        "        top_results = scores.argsort(descending=True)[:top_k]\n",
        "        top_doc_ids = [doc_ids[i] for i in top_results]\n",
        "        all_preds.append(top_doc_ids)\n",
        "    return all_preds\n"
      ],
      "metadata": {
        "id": "foItnoZG2QGo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mrr_at_k(data: pd.DataFrame, col_gold: str, col_pred: str, list_k = [1, 5, 10]) -> Dict[int, float]:\n",
        "    performance = {}\n",
        "    for k in list_k:\n",
        "        data[\"in_topk\"] = data.apply(\n",
        "            lambda x: 1 / (x[col_pred][:k].index(x[col_gold]) + 1)\n",
        "                      if x[col_gold] in x[col_pred][:k] else 0,\n",
        "            axis=1)\n",
        "        performance[k] = data[\"in_topk\"].mean()\n",
        "    return performance\n"
      ],
      "metadata": {
        "id": "XrzQdno_2QEF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_neural_ir_pipeline(\n",
        "    model_name: str,\n",
        "    df_collection: pd.DataFrame,\n",
        "    df_queries: pd.DataFrame,\n",
        "    top_k: int = 10\n",
        ") -> Dict[int, float]:\n",
        "\n",
        "    print(f\"\\n Loading model: {model_name}\")\n",
        "    model = SentenceTransformer(model_name)\n",
        "\n",
        "    print(\"Encoding documents:\")\n",
        "    doc_texts = df_collection.apply(lambda row: f\"{row['title']} {row['abstract']}\", axis=1).tolist()\n",
        "    doc_ids = df_collection['cord_uid'].tolist()\n",
        "    doc_embeddings = encode_texts(model, doc_texts)\n",
        "\n",
        "    print(\"Encoding queries:\")\n",
        "    query_texts = df_queries['tweet_text'].tolist()\n",
        "    query_embeddings = encode_texts(model, query_texts)\n",
        "\n",
        "    print(\"Retrieving top-K documents:\")\n",
        "    topk_preds = retrieve_top_k(query_embeddings, doc_embeddings, doc_ids, top_k=top_k)\n",
        "    df_queries['neural_topk'] = topk_preds\n",
        "\n",
        "    print(\"Evaluating with MRR@K:\")\n",
        "    results = get_mrr_at_k(df_queries, col_gold='cord_uid', col_pred='neural_topk')\n",
        "    print(f\"Results for {model_name}: {results}\")\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "NdE8eAVG2QBE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_miniLM = run_neural_ir_pipeline(\n",
        "    model_name='sentence-transformers/msmarco-MiniLM-L-12-v3',\n",
        "    df_collection=df_collection,\n",
        "    df_queries=df_query_dev\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693,
          "referenced_widgets": [
            "6491b4f67f6044c5b1b1923cf459ea48",
            "985254420ff1417f9044126062485f07",
            "7b1f339a0aa64d19baa1e7ddcf23d88a",
            "2a0b4a20361a4ee5810aef9abeb63652",
            "830d4c1725a742579006ce9a818a0dc8",
            "15f69e8943584217838f2f712970681d",
            "a5e185e185cf4c2bbe7e74d9b6a2eb27",
            "f3882f60a55c4f49b9256704bad04ab5",
            "8967663de8d847b086d7853fac9cb908",
            "d263d481261646c88b8407b591a3ca33",
            "e8cf5d9d5a914a608096061d80ee8626",
            "d41b8ad66c584c5a9b391ddf5175282d",
            "2e6e8f3354fa4802b21df67c2d213da1",
            "867426b6b86c4b95ba8d71e9f9e8606a",
            "6c131e7d53494dcf883595fb7c993468",
            "effb2a1bb0c24e83b245f7b34eda0a01",
            "15d03f5d8fce469ab35b2b3b3a132d5e",
            "12a67ae4855642188946b77daf405d09",
            "d1c6569992d84072897dcffd8516e639",
            "bef405ed5d1d4a01ac036a722eb96601",
            "1e26c6be7cf64b3c95a677cb185e2880",
            "b0c614c3313e4e0daffa94472ce57830",
            "7c32edc9cfaf4ac5ada3bd9131a08441",
            "3123c1dd608b46d99f6845e2cda0ef85",
            "b6ee18e45f444204a6b1499ba124558b",
            "4f418384107d4c34bb46e27f4e35d98b",
            "17d34f4ea47747848361bf3a4980d41c",
            "77b2d9fef4774d3a8d9ef88633f34fd5",
            "06586e026e174a4692043f4d42d50d68",
            "1ea130b510734601b300e8641b9dc854",
            "f8a352463ef648f88ab08c12e5e4fbc1",
            "e153df56611f4e549657333378b1055c",
            "6ff39e086dda410aae074f600227ed50",
            "2e2f325792074f08982714dc66483234",
            "c0c795cc431f41a19b56ba5c05d66ed6",
            "f64d3e1bd9d049faa55b58bec233fe4d",
            "fa7c2432164e495b8fb8916def54af3a",
            "ca2dadbc9fb64bfb8ac3b1cd0bf9d6e2",
            "b7c3ca9b74b44eb49cb4189b0fea1034",
            "f3ee357cf9474347b4afe44cabff9902",
            "7140f6ed6765493a907edc8322874976",
            "b551dbd947d34fc0b21045a789e01e77",
            "83e0733e8e6946e0aa466f12966869c8",
            "ad3c481902924b5d9cc33e67646bc394",
            "f7161d82cc37412f9c31368916f52c12",
            "34022e87cf894d29b1a96e5581191f61",
            "a74a0a3052f04d1c9b5bd3be6104d891",
            "7456f0945e534c8a8ec897ab3c93bf5c",
            "b779a867054a424795076da928c26f7c",
            "ff8ffc827e75408698ab713862a70508",
            "582b084d23a744699122034df6daa2a3",
            "c60ce86ebc7c4074a06d1dde8e960009",
            "cfa4816317a6489ba77255224b0fb5d3",
            "d985a5be24cf40eebaf472c691dc60a4",
            "e2fa821f92e6432da26398136037901f",
            "c51e2206b5004927ad9e7138b4f2cdbe",
            "ef2d81981489411d9238549c2cecd8b7",
            "c66b419bd6bf4aaaaa0ef771d6b13f9b",
            "7d898f1f877b419b88e2490a266d2217",
            "7bdb3b09e347481b9c90bb6a7d1dd386",
            "9735e08016654cee83dffc0ba9e1d297",
            "2e032f2153db46abad8ed9907849d06f",
            "f2a3263097134457bec1f4d71484a867",
            "f2ca56d0204843ddb890ee54a9666760",
            "5af7d0b5a12845e8b12a587cf706620b",
            "429e1f0a84aa4f38a1661a515cfe2189",
            "9265a959d0ac4238937fdf63168844c2",
            "5f521428726649c7acafb6eb4067994b",
            "76c803eb639c474ab9b13f12d76848fb",
            "fc8259a527e847aabc5a4eeaeb8d9399",
            "ee1d16ac8a9d4f89bee30234d27d9a1a",
            "d6ef4b2d41c74fa3a0f8dfbc40665078",
            "4d107f065ba44d2ca317e7c214e3187d",
            "904ede06bd7b4242b6ae19331372325f",
            "c06c9fd6a0f04b4f8a0f07f9220a85da",
            "621e8078d5c243818903cb26da475511",
            "38d195d462924369991f822d46728af7",
            "66e539d2196a41bcadd15364d2ee1b6e",
            "0fdfaf94ac1349c19fab46658f9323d3",
            "da810059e8324c609d5efba64d3ab1c5",
            "8ef274797b284637b5f53a74c72d9fa5",
            "70ccfbd823524360a409e14109aed39a",
            "2a97231d7f3e48b6aacbb5ea61215aed",
            "8804bfb313d245199c9b90cf50cf1e5e",
            "753c7cfd3cc04740ac10cb92435118e9",
            "51e4a9cca96346f3a2dd831e52dbf4fd",
            "0a7dd71070f944f18f7095af747ef789",
            "5227ee90bd05455492f9004427d8286c",
            "a2587467834046aaaf4e686e782b2da6",
            "04dee855c98c46a1a994fb93ed2c241c",
            "57ac1a33ac254d919c349c9c71c97fe8",
            "6f4e33423f274b9687f2f785001d5d7d",
            "12fc9f15a67346a0b70977b1998ba4e4",
            "c5d84a74345a4516b31ef4fafb407354",
            "6301a3b0cc6f4d63be25093f42af80f0",
            "0e959ec152c44187a3263799fc8f74d7",
            "eed35ce27b1a40b2bd1a17e5385a4be2",
            "0a4e35a78d444a78a65d3739a6b3137b",
            "9cf792c2a21443f9a0e01db9fb941d9b",
            "0411f0f4a1c840e997b376870131fc3e",
            "de99003490bf479f8649fa101d87d01b",
            "25672af8d625403aaeb5f6c6f2ac199b",
            "423db26befc14cafb743b43f6932716a",
            "7df250165f5d4f158734eb04b822073f",
            "9a8b88fdfc954bfdbed0d8eb60932876",
            "e181e66d6d5f45779ae8ef37677f8426",
            "e9be7afe3d0d4cdfb592cb94803e5192",
            "047a3d770d7442698185e2a84a58747d",
            "3f89ab12cd744912b15c942f9eba9b09",
            "fd5c41c439e14f05a48a9fa27a2cee0e",
            "820c338dfa204f9597644366e76d437c",
            "dc5be76042af49b1b501f71a26d1027e",
            "604f85ac3be447f786c3002833366cf9",
            "e584a4a977a94646910f128ed05af982",
            "1680333055b8474d9f09d417823e6b7d",
            "15a9dd9b88e541139b7615b60e7c2523",
            "eb72f5ac97644cdcb6ffbe6ec312157a",
            "11d641145301460d976d28e9138a6508",
            "c37ace60cd744c3daf896cb6fad68d27",
            "c4e87f4790104a67855de185c5e06ae4",
            "99378d9cdf194681a006d216064a49dd",
            "6b5c114c031346daa08efc2581d1c5af",
            "c7d45e67d3c544ac9284af0e1de63248",
            "9a8a66d0174f4c2fb29c7e7d7f814da4",
            "44fce3c125d24a6f871f5020b88935c0",
            "b5b48c428d984f1cb481098e90a4f94d",
            "92278babad274e0f8ff032c0613d21c6",
            "b27bf6cb55ac406e8b4dac8ff5c6b9a8",
            "fcff09789a864f64b1ce6e34aa7c360b",
            "9b896feb528d4492bc950edef07e6eb5",
            "892294c602224dfa9f2d80d7d19cf817",
            "92a5f19bd3ca4848be09ce5c241fd50b",
            "3c8c19ee0d174b2ba16c90797e448df3",
            "0ff5bde0c4ef469b856afb3b336194b2",
            "35320ea0ea0847c0ba392abf59dcd729",
            "0f63ed1a5fb04a5f8a4e722820c1ffd3",
            "4b37c2bdf21a48698fc0c6cb9b2bd608",
            "45b98aa180df430aa4388a4c4bb7932c",
            "89abf5e7e5744e619892c0d7da7a8d96",
            "b242eaeab46c4cea8c9e9b9798f7513c",
            "1475708dee1b4aef82ff73e03813fb2f",
            "3f34b7a3e3244fd29d5aaa659316684f",
            "4a8db2becfd841a2970fd86e2a5d2d50"
          ]
        },
        "id": "GHuW3vyV2P-E",
        "outputId": "36f8a50b-096f-4f61-b303-509649b3bddc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Loading model: sentence-transformers/msmarco-MiniLM-L-12-v3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6491b4f67f6044c5b1b1923cf459ea48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d41b8ad66c584c5a9b391ddf5175282d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/3.72k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c32edc9cfaf4ac5ada3bd9131a08441"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e2f325792074f08982714dc66483234"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7161d82cc37412f9c31368916f52c12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c51e2206b5004927ad9e7138b4f2cdbe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9265a959d0ac4238937fdf63168844c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66e539d2196a41bcadd15364d2ee1b6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2587467834046aaaf4e686e782b2da6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0411f0f4a1c840e997b376870131fc3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "820c338dfa204f9597644366e76d437c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding documents:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/242 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b5c114c031346daa08efc2581d1c5af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding queries:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c8c19ee0d174b2ba16c90797e448df3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving top-K documents:\n",
            "Evaluating with MRR@K:\n",
            "Results for sentence-transformers/msmarco-MiniLM-L-12-v3: {1: np.float64(0.34785714285714286), 5: np.float64(0.4126428571428572), 10: np.float64(0.42183503401360545)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_e5 = run_neural_ir_pipeline(\n",
        "    model_name='intfloat/e5-base-v2',\n",
        "    df_collection=df_collection,\n",
        "    df_queries=df_query_dev\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523,
          "referenced_widgets": [
            "2a5d4e3d3fa343348c2c9143cb340136",
            "78fe3f1c563541ff9cdbc1ed9c8ed198",
            "5749e1111bab4f52bf71d0f4f32aa7b7",
            "dee782138b114c8587ccdce3e6ca7802",
            "0160c6a1b1184889b5b1032a2dc438b2",
            "63d97bfb08554790a28a66825b61c430",
            "653eca848a2e40d1b144a870525ffce1",
            "410fefc294ea4388a9343170b5db804f",
            "9f8ef3cc3c0c48108c2498101440ce92",
            "b278806d4c3c4aaaa375ca51b7bd7f00",
            "b9d2feeda32f4d238e0bb8bb12c460ea",
            "2622447549b8452783e891fd85d6e6b4",
            "3186b6b376f64596af460457fce07e82",
            "5d903ab96ea240529af700401b267a2e",
            "4f0c26f61d014a7ea847d870b17073bb",
            "9d55f0a4248b429e9b056bc7140c89c7",
            "13a62f13b968444db7bb288c966343ed",
            "5253405e9e784459b6e332d95f02d795",
            "443813c000744b618a18b8d3ffc1ce8d",
            "8c7c60a241e24897b092a8f59d0daa38",
            "811aa30a89bc49948f8c2d7f9b129494",
            "34fdc856ddbc4ffe85c97cf0a25f33f6",
            "473ebc115b5e4ee7a72f3c0be533d2a0",
            "b37b4f08d45a407faba4145c85e160de",
            "f3c5b11a6cfa4657acda0922b7df2fc7",
            "0560769fa5bb4399be27d13693428022",
            "ec55859866884d329dd4138b673d7648",
            "8bf3cc134975409bb20ade1eba321ea1",
            "16da15da601f41ccb27e9dfcdcb2fc96",
            "e95592b0f3774ae8b74a5a109988f903",
            "70da3cb9533b48efa11a2697dcfdf8c3",
            "02d8bcb7916a475494b47d2581b2f78b",
            "7e4ffed37b484c0c9605e3b554b1c4e6",
            "d9114113ba4441b8924bfab3338d0460",
            "d16b032f11f2438ab2516edc3fc54e21",
            "ec94a4399338429a95bac705c9b00241",
            "9022687656f348c1b8fa0aa6cbe3e4bd",
            "5521199ea9fa42d1b148ff4996ebef9c",
            "e9613296a2cf40679b94c7c6885aaee2",
            "03afc6ed0fe94823b04ae6245be5b3f7",
            "cca39c70915a48408343965bd4d317de",
            "53a6586f41994635b03c5a6fd5c49764",
            "a59c31c51ebd465fa0820c34af1a6680",
            "b14335319851430ebc17a74e638f81cb",
            "c4b02ee1a8894a2bb72f7f2f98ee1f02",
            "31d6c483888d4833ba515dcfdf87640e",
            "3a555d15141e40b9b3cb4023bcfbbbbd",
            "6ae3228c0a734948951aa2e1ac158370",
            "521e8b1a6405455abdc0c1c5b962a3af",
            "9b3c221ce56448858fdd619966ff39c5",
            "a0824dd5cbdf4978ab6f11e694000053",
            "460aa366f3f04432a219818d4645b206",
            "a87f56f797584221821fa0c2e26a9a37",
            "3ea007c824cb4e48b40e468772d960b3",
            "cbd970047e3646598e0472b06da1fc2f",
            "065ce784ca804ea88d36f74f4e8998e5",
            "df5ee65436284493baca69647781e279",
            "405eb0ae2c9a4f5f90f5c4979c049f79",
            "0783de904bcb47b595faf205a649e064",
            "c5f7055131ab4f66b039aa764867ccd1",
            "46c088d3b88b4852a67dc045d6374c23",
            "e41346c14f45477abaa4513b81633ebd",
            "2965357743bd47208e67bd469bb8ce71",
            "99020448790041659421423a4ad050f8",
            "7403e73539594d3e919086303b19bc2c",
            "ded09c63c5e44f23a540feb1715827fe",
            "87b97b9540e446acb962a159b19c6b66",
            "a6b1de62df67480baa863f56b74f0ff2",
            "534d28b8d6434d2daef17e6f4b8b5595",
            "d881d6f99d5041e2bb87702853a60d60",
            "28a6e7e149ee4ed5948fe1e0c9ccdcc8",
            "945ba021366d483986f590f1414f4138",
            "ccfcee61341e41d5b8fe7d7969ecb955",
            "aed9cf80ce044b26baa5447e448d44d9",
            "b9976ab90fca4d3087bd8644fd45687c",
            "ef3aff6c640549549b9dc2a0df36a15f",
            "197df410a7ba40a7877e314a569e5e3b",
            "aeac53fe279b41a2a568e723a61b3873",
            "93c40be87bce4ce99dd64d2423fdd207",
            "7c8fd2bb609f46118554e38b2a1e2a8b",
            "8d1ad439222243eb943b7281108bb810",
            "38b51d9bb98940fa94f7a5672a24a0f7",
            "f5e72727c45e4778a69a8f900652d1cc",
            "864f5db00cf9426b9d8b9aa5fad53320",
            "6f024a60d3eb4ae1b3dbf12088a4cd24",
            "5c33d9cfb6ac43d78c1b4911bc333815",
            "b94c741dc1004acd8fc5e5b6fd6bc2f7",
            "66db06df0fd940e8865586d6c0e252b9",
            "53fb94e7a2714fe18c45f481be0d18ca",
            "2794d78629e24fe2924c33babe9729f3",
            "ca697925433f4f64926591568caa1379",
            "8279e2d6f6334478a40f2d5481283df9",
            "451c3dc9e1804ec0ba3c6ca7bff7b20d",
            "7526c860be0f4533b43252fdb219d0bc",
            "25f2115639d44156bb6ff7f3de5f4538",
            "1f7e2f12c0fc4827a398fc29ff70be7e",
            "3aa6ace1f5734eb3bf802c970b4a0519",
            "370aa763db8940579852ee2f4a9c9779",
            "ac66bfbf80d74beeb1a3deb8ef45067b",
            "fd529d25f2dd4bc9ad474597555d985f",
            "902245f2a5144216b86f9a597d927fa5",
            "3fbb3b2b616f4eb0954869ef2d65cc34",
            "cf404ea209a34c39b406576f1e60182c",
            "b59a1a4d61f840a9b86a2f5fd8c2ecf6",
            "bd58a2b684b54a6bbd8aaeb4b05a821b",
            "dc0617d7d86b41e0a59ac76559c8e33f",
            "77b2954b66ea43be90de23c656537eda",
            "693d2395c06d45ccac9035d93d55fa14",
            "a18cb40ca695443a836ea858131cb89a",
            "c4127abd6d184efc90c3194fb0fd4b15",
            "72bf203f38214eeca7e407ff47656acf",
            "25f98215e1d347eeb5395ba1c6779026",
            "46028b4b56ab48fc999c3187e25aab2a",
            "252ed01d006546a5a63b9ab0762920ce",
            "b3a9f5c72ee949de81973afb34313e52",
            "e08ad1c175184b15b492c11cc58f7c84",
            "53292a6e99b74f30aabfa0d572854059",
            "41c208d0e65a4183b290f4273f49f3d1",
            "840d9be2438746949fd7b356ec5d749f",
            "dceb9f33cbe449d9af186c6102388e00",
            "04473d78841f418f9a2a7b4e3ccf6342",
            "7dbafb75ed2544a1a50b65ee7e5cbb15",
            "b17f5045dc7a46a18e6a24e5e97b8ce1",
            "7106ebb9f4164f9c91c593fca2275d27",
            "278c2dc81099446bbf24799d0e18711f",
            "4b53de6f281542b39960bc6fade616cc",
            "dce42cbf20bb4cd5a4420be660f6a527",
            "7f7d4376281745a68fd66283175fcb1f",
            "5d216eadb8a14369a89e3717be4489d9",
            "24e2f1f2152a4d25bef7847f3a42da52",
            "7589f4f0c4c948c3b1d77a841d2daebf",
            "6b29b2f92e6743ae93299a59084fb971"
          ]
        },
        "id": "T8T3Oapy2P7D",
        "outputId": "e7bd45cb-f3c6-40e5-b3d5-59e3edd37342"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Loading model: intfloat/e5-base-v2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a5d4e3d3fa343348c2c9143cb340136"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/67.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2622447549b8452783e891fd85d6e6b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "473ebc115b5e4ee7a72f3c0be533d2a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9114113ba4441b8924bfab3338d0460"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4b02ee1a8894a2bb72f7f2f98ee1f02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "065ce784ca804ea88d36f74f4e8998e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87b97b9540e446acb962a159b19c6b66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aeac53fe279b41a2a568e723a61b3873"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53fb94e7a2714fe18c45f481be0d18ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd529d25f2dd4bc9ad474597555d985f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding documents:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/242 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72bf203f38214eeca7e407ff47656acf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding queries:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dbafb75ed2544a1a50b65ee7e5cbb15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving top-K documents:\n",
            "Evaluating with MRR@K:\n",
            "Results for intfloat/e5-base-v2: {1: np.float64(0.54), 5: np.float64(0.5994047619047619), 10: np.float64(0.6070802154195011)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_e5 = run_neural_ir_pipeline(\n",
        "    model_name='sentence-transformers/msmarco-distilbert-base-v4',\n",
        "    df_collection=df_collection,\n",
        "    df_queries=df_query_dev\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589,
          "referenced_widgets": [
            "95c74c6b886f4b39b212641c7727e0f8",
            "89ffa9007ee5483e9cc7ae44c34abb18",
            "68c6c0cba1ec4775ab857ca8f4319fdf",
            "48bec20fc46e4dfab499a23641d4e273",
            "cbf82166b8f6438281d8734e24030efd",
            "1cac7ae56fcb425f9da91a9767e4319a",
            "470da249e3b147eea1da3b11f483212e",
            "58ef28c7b67648fa9ac966af5ad3848a",
            "e289eeb51f164387830c81c6d954d153",
            "9eb6c2cd18e248788f6e5b7c5925e53e",
            "75a235af22784a0888b198b0fa6f2f8c",
            "7c2f643dd73e4c69b6554c11764bbe25",
            "fb1de953b1f143ea8d8faeda9373ba00",
            "91b73441fa3c4716ad9cf7148981f276",
            "94cbcb7bb7284fb2a4c3c280202f6898",
            "ac3a987aeb714bb28bed534ad1177bee",
            "81000df2354141be96702f8c01e70a65",
            "0e14c2dd2a1746a590c3dc86653157ad",
            "14fd168169034af5899f16a5d78df482",
            "551f3fff736f46c8bd986238a1b3eb2e",
            "9ad921b88adf43ab8d0b35d3ccf2c8f1",
            "0789185bff93477facccd6afc2b3e4e2",
            "d0618cee195e41a4b4299449485e80aa",
            "dbc5477c1d59423ab5140fbd44b4b229",
            "9e0eeffa5c12480e817b99f1509c539e",
            "12e0e11f900b44c2a2004a02360674d3",
            "b6b682540d164d0db16a272fe1fbfb07",
            "e34a24271d2143dc931df4825d44067f",
            "db3870cabd404cef84f75c0845734b06",
            "3231f411fb6341c3b6008423ab9207ca",
            "54bfa76b713c4b0b971115ace3477f21",
            "5a90c4fc29044e0da1acbc04afbe4a8b",
            "2d34719116014deaac3ab9819c28e74c",
            "58584da69f6b48de98be35f5594476c3",
            "c48298d06c8f4ce1ac976487eaae1030",
            "41376c9e8a38405ba5088ef194a39d7e",
            "38dbca25aa614f3997f17e5be97560a2",
            "8b08cfc8b79c4ce4b33b984d8d8f4993",
            "0a81a0236bfc46e8a4ce23737000438d",
            "e80b0fd5469047acb5babf4b36a56489",
            "c22fff23582243a7b72c12a59e940904",
            "09078e19ae2b43f3a47c781a19456da6",
            "e8904665dfd64de080c30d7dbdb00154",
            "e4ba656eca064292b93cc59e8f3438d2",
            "10f0972e3675400db7009eb1153e733f",
            "bd612bbf487e4071ba63ed14a34dfb8a",
            "f893e22400e14163a831fbf27fa784ae",
            "636d9a8b507445b8abb0eeb54c987d2b",
            "4f7ae5ccbe02449e88d0abdb2a262801",
            "8e3773f0ee894eb0a9b26ef8a105842a",
            "6d9741e816814cacb2c4b824145c8470",
            "031f31e7a8e14452a8fee291b0f43cc8",
            "3cf2db8822874c289f63c87b0b9664ae",
            "861a23e2b36b43f9afc7ee18338a1959",
            "28a3c202c270454d8ee2c7f125808ba8",
            "4d957c62b7d942ec86a8327b3c116ca6",
            "18a06f83d41947ed866f04994b6f2d4c",
            "4174586a6054465dab3a28a189cc85a6",
            "cc2db6ab8c08493e9bd293473dad3de2",
            "21e1aa7eca084aaca8090b352acbffd3",
            "783350a23a53401e9adceaa65bb73f7b",
            "fac558649b2642fba0ce074ac5f66b9f",
            "9a2d0a13f30b4431adf4891ea93a763b",
            "e6db8916e912469891755c4fe0991562",
            "343d5f9c530f4af2bd55855792a39c47",
            "591ec84c77044c3fbe7d7f7cd759fd2b",
            "8bbeb4ea073e415a8384b06821817d56",
            "0c8470f2a8f349b38e8f409c211b4cbd",
            "a6d93110405b43f392fe79545bba2c39",
            "02cbcdefaa534c56a74624c420eefb4e",
            "39a0de324ad14f72ba0cad9e8cd601b0",
            "8c743b4351ad4331913c791fa829673c",
            "c4a0c9be59344dbeb8b50f87b92da38b",
            "30e6c510f0b6460581a0314f5ea38798",
            "7d0b0a28dd4e4916b3ae61935079d5d4",
            "3c4a07e50d7240259a9e63244d128f1e",
            "b466f739dc23402089dd40c5c4960997",
            "37dd760aafab428c814cc3231d71bdb1",
            "04bf8c2b82024975abec9337fdf7c82d",
            "a82c6d2f3b574f10a6c9fce154ed2bed",
            "a026d30685814e88917a61335c0914a9",
            "c08eb7ef775641d18bde7116aaf9a214",
            "1d07953af88d4ef49966d9aa9824dd42",
            "033350de28964d4fa9a9b2883db1006b",
            "3af58bae62e949bf8541698085073d6d",
            "ba97642cbef94af5a1e5806c4962859d",
            "ec7f85b6fa2642f9b37ca2ab651149dd",
            "31059616b4f041a288ced5495d87867a",
            "e721b842a54b484193f9555df768bbe3",
            "3d1c08180bc14116a06719760bdf2369",
            "51ab41bf9541452fb195c6fbd0ccb348",
            "74a14edcac99422c8d4d98fc0e90408f",
            "769eeeb88b944e1a8db9ae087b79a230",
            "c9f687e8e1c249daaffb06413dd1b708",
            "266227078c1642c5a464f954e7effba8",
            "290322fb7920415e9d3aee236a3abdc4",
            "a8c30247fd0a4df682074ad7cac9147e",
            "0dcbae5402974f2a988e0c9068ba4b72",
            "0f841f6d903c46d28def89f56db15048",
            "c77f2d9cef68482b8fc9208ea6753623",
            "fbb766cd871e457088e004c6519713af",
            "0ceec273cf9c4a7bb428280c7dc02eff",
            "a97331d26fae46c780c211b1b7934203",
            "33179b23b2ac4904a8ac48a40861866a",
            "ca6a4736da2f4a2187af41f8638bd15d",
            "b47c4296fddc4a10ab7812657feef634",
            "e0b205a4525b4b61a53033846f012583",
            "5487230c4c6a48efaa1cbb8a9c15142f",
            "785ecd05be8f4e12becf75d10a9f5ddc",
            "89966dffc54c4cf1bbcb3f40e748cdbe",
            "a69b827883ed4e9d85b43f16e6a35d4d",
            "e93df87a8c68405ea146e1c5b0d80132",
            "b2d35f6b1c41408f9912648456eae8af",
            "5b78ce1d01e64aeaa686caeaffd75e29",
            "315d1d416bcc4f258cdff1b4752a7a1e",
            "70d7687561c94d7cad8d2d62271d9376",
            "7749ec449e174cc3aa34a1f1a976c7a8",
            "04999abbcd4c43dc9db8a691ff4e91cc",
            "55d5182f1b534b45ad23123ba0700318",
            "71ea296f5b514c5d93dbbd88f27fdbef",
            "f1b4307f945f41dd988380003afcdd18",
            "95ac2cf82b014250ab18e92bc45dc2fc",
            "c7d6802568ab439c9db6c16987394fc4",
            "b1248bc2f3054423afaaaaec83f1c4c6",
            "c739db7bc3b84feea113bff28a270f4c",
            "46c148d2788b4ecc96208b7ac858d19c",
            "004a479372b242da8f404eaf029159c2",
            "4a734b4307bc416a9f16c4434a547048",
            "4ff0554261284c188d673c657632217b",
            "190ac129ec9c47eaa6197c6d8dc18b80",
            "1588163817b540bf9abbbf870b639005",
            "376abcf973a3421e96a52dbcdbfb5699",
            "9b7fd2148cfc4b63bef9ac3f4c635a76",
            "132c776e30764ffd8a4c36258620b4b9",
            "15f4ce1667064fa28fd0725e9a45cbf9",
            "33aad19025c24a2e9ee4dbce8c1174a4",
            "cd13c7ca1d314f86b9d211ee1b28b2e4",
            "2491eb2e71ab468ab69a04d91aa89d85",
            "55472868da6c4ac299ce7d121db535a8",
            "322e6131e323497dbdfe5aa1868a78dc",
            "b92a1e199ef5458cb5c556ee3e714d24",
            "55a3c2a88f6a4a43aa14ce4c6f8291c6",
            "83b54c910a4846019085ccea6aafce45"
          ]
        },
        "id": "GqrKMmZ02P0V",
        "outputId": "6e99c124-9e14-4ef5-f292-790c1a3cddea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Loading model: sentence-transformers/msmarco-distilbert-base-v4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95c74c6b886f4b39b212641c7727e0f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c2f643dd73e4c69b6554c11764bbe25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/3.53k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0618cee195e41a4b4299449485e80aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58584da69f6b48de98be35f5594476c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/545 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10f0972e3675400db7009eb1153e733f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d957c62b7d942ec86a8327b3c116ca6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/319 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bbeb4ea073e415a8384b06821817d56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37dd760aafab428c814cc3231d71bdb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e721b842a54b484193f9555df768bbe3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c77f2d9cef68482b8fc9208ea6753623"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a69b827883ed4e9d85b43f16e6a35d4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding documents:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/242 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95ac2cf82b014250ab18e92bc45dc2fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding queries:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b7fd2148cfc4b63bef9ac3f4c635a76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving top-K documents:\n",
            "Evaluating with MRR@K:\n",
            "Results for sentence-transformers/msmarco-distilbert-base-v4: {1: np.float64(0.365), 5: np.float64(0.42802380952380953), 10: np.float64(0.43436281179138325)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_e5 = run_neural_ir_pipeline(\n",
        "    model_name='intfloat/e5-large-v2',\n",
        "    df_collection=df_collection,\n",
        "    df_queries=df_query_dev\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523,
          "referenced_widgets": [
            "bd6f15fa633041aba6e573eee938388f",
            "a7832a9a655145e58ead08666ed0be3c",
            "a927db6cf05646cab67f4a3626e2309a",
            "1faca470523c4e73acdaff9ca1e33e64",
            "2c56b4db3bfc4658ac937e070133ecdf",
            "d2204327fc7d4caeb0a2ce10d4ccf654",
            "e957447a2e3f47c7bcba4e9993e8108b",
            "b56092d5b1db4e5d9f25f385bc5e469d",
            "a365ea77576c4444b921a6816f123484",
            "3eca4ede8cf94160996b6a3fb91e9214",
            "349e3dffcc0e40c09c0346cc3023d8c7",
            "1b7c7e3624644694add95b92a39279e3",
            "88e48cd9442343edb5098890c5d494e2",
            "3c0166969ff14f7e917e6b0cfa7df035",
            "44699474f9a64db9ad82c8c44b1a763c",
            "5e5ad278c3974ba088345ff496a64cfa",
            "877c9f4cd0a44b64a7b5caa976be8152",
            "7c3a47762a7442728d187fbf1d17ebfc",
            "49e4a4ede0544266806bec2c625a21e1",
            "5cac3521515c496b80e8938004a581db",
            "2ababec8ee6a4b379e8a8a540dd940ee",
            "cc12bb852e7443a68871cf585a3855a4",
            "e6f19566f3264d4585c5c037cc1ac6aa",
            "6fc46b941cde48109a9eaacad361b4fd",
            "27e4ef3661324e17bfa23f6e6336983b",
            "9dd829d8f2e84a328f1addf547e7053b",
            "f25e22e2e5784ac9841dcf3633db82d5",
            "3f6ba3bf058d4de0a994a01343bd6417",
            "12b7671388f74069be8bd5a288bd9cb8",
            "5a50d4c9f344401aa5baec49319f06d2",
            "113fb8decfd74429927309b73285c036",
            "f6737b5c16fd41d2a787047fc59f5cb5",
            "5feeaeb34866470584dae5dbc95b69d1",
            "b098ed7dc6ac4b8f91200c383dd40108",
            "0d9b8e5b7383459b805ef0135e7651b3",
            "4909e661e65e4dbb8234e846bca53b1c",
            "b15115fa125e425a984708120f646803",
            "37864c802ea34c79877ea3bdff2a4c7d",
            "821ccc2b63ff43679e573c4fdde709a3",
            "b2ab46783fc84f1db2f4f119cea2672b",
            "04f178a87074458ca55cbe8b8e7340ef",
            "884021e1f3034bfe870f4d563106922a",
            "34cc5d3ae2e74c96946e7c7e2468d791",
            "c9c672d6a2fd406286d7b07230e7bfad",
            "708667455aa74b468923fda865f01509",
            "e9412bb16c61414bbeef9ae3b26f94ed",
            "40713e393429494baa00b24b38fd2658",
            "e8b86aaac04e42a089ff32ea2a5fd67c",
            "9201a16c992f49738f4e1de2928b93d8",
            "cbe88d140b184a538ec70eceb8c1465d",
            "a255c6c2e5af4da4a46564df9a7786e5",
            "e1aa9fbdbb5e4ebdb3790beb0c793649",
            "ef25a845e92d4e26acc097cedb904b6d",
            "885bd94f953240aa8ac0f026efe4b280",
            "2be178972fc84f4c97f939eda809ddf9",
            "5787ded181674eb39847927544fee184",
            "d0eddd83c7ae4fbbbf446e44bec936c2",
            "8c5d73e2d52944d5842230b1638f60e3",
            "1ac57b249c734348884b79e78d35f27c",
            "64d4b2f3cf444d96a0cfc1ab9968c837",
            "7255430fc82842f1a92bfbcb79440126",
            "7e62b2d708814216a47677c8d617b838",
            "3a59a164e7d84209b33c91e5a1cc0940",
            "c67678081fd44fcfa416144330530194",
            "67e9d21b62b94fcb8c99a68d2f02e0ed",
            "f8f15be33c8340de8da9cb4781b4e50f",
            "e563660ccf564d4f947dfe2c1b027635",
            "cf797a436a7142248a67a9a3adf372d6",
            "089b7ed42f904179ba707a8142675094",
            "48801419b0314d04a02a9dbe7c7d1fa5",
            "1a058c53a27f49ec8ae211b58af7a445",
            "768b64d2c8c34df5a2bcbc1a285c03c9",
            "2560eac78ab44c64a0264cd0be163cb6",
            "6e619f6d513c47509ab88fe753138b6a",
            "fd64e2e5907842b0bea22c2a9cdfbe0f",
            "1bae052d742e471eb5f28cd2fbffb23e",
            "f937fbaba73247b3a0f501a599d7b714",
            "76bd868411cc4dfe99a178ed26e983ef",
            "202bcb0d168e43898e62dbf4ab7dbfc4",
            "bb1998ebee724d50a6f46ca4e4918d15",
            "2b7fa8925b8044649613dc6ebf0f4a94",
            "e8627bf877ca4b438efa0f71c86575ef",
            "82fb8f5febf646c9b7c8771897df1891",
            "560fac9f2e244baaacdbb684a1c32f8f",
            "448850c90d66469bb7bd5ccb37055948",
            "324e38b291c2464289a2ec190d4a7c9b",
            "cb7d84e4b96943729262b53189f1efa0",
            "6a50863c32d94f448a53601ceafcae4d",
            "9d7eefaf2320462b98b3f7e56151c63e",
            "949eaf61949d4a659e9babe084b12f5a",
            "68aaa429d2f040c2b25c8f43ae624425",
            "fd2520eb9ec94a4985b1ea3e164fdf8e",
            "a8e76eb7b36c4efb98f52a13d9401a7d",
            "f727725227864a6eaf3cf4194d691e14",
            "83b745ad18f1495781f411bf7b18f7ab",
            "f079c7f623b44967b6ae1a6ac1cf0ac0",
            "e9ee3ac86b054a37990e994d62d0135c",
            "b229cd055ed94e27afda7980e7d56461",
            "1216c0619d17418da4f303d15ff49469",
            "1945dbab7ebe4157a51379f6ea4d6eeb",
            "ebf303920d3e4075a4c7b3557bed30d6",
            "c763300f85b64ed29bff77fccf222985",
            "848cae69cd2d493e9baa82425876f7b7",
            "5741d71cb71c4dc9b3b98e4d388fc15e",
            "daefff02dbb540f699c209c9f618ccf7",
            "bc3440a8cf9940aeb04e81bc220ae68f",
            "bcd2ead36d224ef4be735dfa187e8518",
            "90c9ee5ebfb64a7aabc5351f92ed34fb",
            "e4a5ef689d0b4d9eab90f9c768f03cf0",
            "4683928e417443ab84c0cc485859d4c4",
            "4c345b04b3e842e39b66bf4b0255882c",
            "3c9f70a21e634382b552abb5c0c8c312",
            "a4b7bcb8c4bc47028fa8cd539b01e522",
            "423ebfb4893a4a7b9d41f7f66cc9bf9c",
            "9ce328ff5ce640319f8809a3aeba4156",
            "8d93a47e9d5541fbb65c7fbd088f8561",
            "a80fd71e9c9249c3832fb4dca67fc2d8",
            "67bf78f9a6184f93b91c32d3041a72e6",
            "1fda9b8b880e41db8e27fefccae2f220",
            "0a2487c62f1f411094b19d2bc3b07d99",
            "460f5a1a3a574551a64613e4e29baec6",
            "fe75d100c5b046559732bfad90b84d67",
            "aa7d8fd5327548f494f43ed45c40328d",
            "f51fb0de9b72416e9d8ae18d9e167436",
            "52e61c4a1fab48aea888ef32ecaa7c13",
            "f81f3789b47b4eb4bf6bc4eb4ea0d67c",
            "02f99b3a519441d69a19c13e9361d971",
            "efca76e81b7b4cd68f7fd5888c177abc",
            "d0ad03a05f3a4be595c04eba92c9a1cd",
            "30735c50629347faa794438bbab3358a",
            "973ea67e3896495a94668af55a05adb2",
            "177fb608129a49ae8ca77aef3f40e331"
          ]
        },
        "id": "CGWY1sZW2PrN",
        "outputId": "0c9cfbb1-b2bd-4ad5-a664-340b5ddbaa1f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Loading model: intfloat/e5-large-v2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd6f15fa633041aba6e573eee938388f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/67.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b7c7e3624644694add95b92a39279e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6f19566f3264d4585c5c037cc1ac6aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b098ed7dc6ac4b8f91200c383dd40108"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "708667455aa74b468923fda865f01509"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5787ded181674eb39847927544fee184"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e563660ccf564d4f947dfe2c1b027635"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76bd868411cc4dfe99a178ed26e983ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d7eefaf2320462b98b3f7e56151c63e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/201 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1945dbab7ebe4157a51379f6ea4d6eeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding documents:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/242 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c345b04b3e842e39b66bf4b0255882c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding queries:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe75d100c5b046559732bfad90b84d67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving top-K documents:\n",
            "Evaluating with MRR@K:\n",
            "Results for intfloat/e5-large-v2: {1: np.float64(0.5771428571428572), 5: np.float64(0.6394404761904762), 10: np.float64(0.6460663265306122)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_e5 = run_neural_ir_pipeline(\n",
        "    model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
        "    df_collection=df_collection,\n",
        "    df_queries=df_query_dev\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589,
          "referenced_widgets": [
            "292ec25764964651a43e15f23dd247ea",
            "19874cf24ea940ec8e5d3685e3e42b35",
            "56c5d24bee2c43b6b07438ceebc0908a",
            "6726759f3a3446d1bec08fb786fef8ff",
            "25c17083a67f4208a5a158b2b1536e0c",
            "cd941a6a7b4345c5969f0977e9ceb2cf",
            "c5900506546e494e8f63191f56d4890e",
            "02bb064dfde24f82a1e3c7fbc2d4bdc5",
            "4e614f581b9d40abbf395edb119e09f9",
            "66642f3778ee40a99a64787836d59a1b",
            "8d8fc8acb6e64ecf9da554948d83589c",
            "6a7ce3711ebd476fbd4d949e50f547c0",
            "5af3bc93a4f54fdda2bc6dd5285980a9",
            "3cdf782c63c14210b56159ef51603eda",
            "858395eae152420d978bb7c4ceda2b42",
            "28194a0023e14b41beb0c226c59f0ae1",
            "091248eae7104a2797b45520f0d8f22c",
            "51de169b929d4bf3a1813bddab819abc",
            "78eb7c0c5331403eb828498e9c0f75bd",
            "0664a92718e94c54981532679b80056f",
            "96406c5e04ed477c8f0f5f97cc836842",
            "6ea467a422a843eb89522b57327c4a39",
            "9043bdef63924fea9407d6f7183c1665",
            "ed051fd1c7ea4f87bb2d644df3ad2d89",
            "6d04fe6a48b447b7b7c9b8c9e0bbc372",
            "b061679711ed48e0b1e536ec3eb406ce",
            "9a761c2e7e674f268141d08dc5af9e5d",
            "cf979e1a4d064f7e84094bfa46d2fed8",
            "af794b6542a14cfab5f2020ea6707b63",
            "26957dc1d09e4726a81bf5d5c01afb43",
            "2a2f6732a21e4bb695d24ad246a4c6e5",
            "a85ef44601bd4284b0e61ea95f39daf7",
            "f1d901e13d9e436f82936227c00b5ce6",
            "8c9c64c8047c46798b4a8907da9f9b8e",
            "fdcd2e0a151f4eaaa8652b6abb6da31f",
            "8329d589bab44c869921f296843e878b",
            "71a29f18dff740c5920b4f38607de5d0",
            "dbecdf1549e14000a8163bb77978b3f5",
            "fc9055eb76354e648951e2adbc7fe2d2",
            "ebc2be27bfe14bb39029e09a372be24d",
            "ae124c38925a454e9cbf4bd0618d7310",
            "8b56354ed4734c8d92148aa5e1d7a2e2",
            "f86166d1323d495c9b38ec1c0be928cf",
            "0a1a077479bc4b3fb73347d68c81e64e",
            "44c50dfae7b748cabf72954ae67a4ffe",
            "004c42b7c759478780de103bddb6ec83",
            "1c190cd2d3bf4e309e1989862639cdae",
            "72ccd2d11cfa4ff6ac346634f48a8623",
            "931c954ac36442ecb731d9e689f158e1",
            "89c7aea4df8747ae8c4925f07298d31e",
            "ea717180db734be3a3ad4e12677765d5",
            "5bb328cd81d141039093151fbdb44cab",
            "9709cc08bcb747cca9d919b8b2e85fd6",
            "cfa2b935815a4fd19595122b46689b81",
            "2734fb129a1941cdb57f5c9b4ef88968",
            "ebe45b507f0340ff9e476a151c6fd2af",
            "1548018eb8224668b316ea8d6ab0b137",
            "e212e040e853430b93010e5a606901ec",
            "d4fe3e2c48a141b3a75326fa4a3deaa6",
            "798cfb39b3c74c14925b4dd0608f9a09",
            "3fc1f27b8fd44c7598768aeed659aea7",
            "f8bda6947db147de8221280b3ac5e743",
            "d31691fc82914324b06ecf02e1b0207c",
            "b92e5ce592da41569aecd54539913713",
            "1e9b248a8fef4edea956d51bb7910821",
            "4ac18ccfa29f4753acdae6de3a722f4a",
            "830297a2d3874fb4bd233947364a8b92",
            "ecce46f805df45dc949bdda8601bb0fc",
            "461ee129b79e41a4a513b8ce9c7743a3",
            "1837c078e54241f890db12f9d05dd66d",
            "eff1721495f2494187b14af535bca296",
            "c2fe1955c2c94e4991c4647d038e6c84",
            "19ff925a808a4928a644cbfc73dea5a5",
            "4ddb089eea3e43199abbdb7d43aeb8bd",
            "9fd1ae75a7654d3d92ad58335de36a93",
            "16a3dc8d34c549028d8ee2812ec6620e",
            "4e027c6c272d4238a97dabfa32d3bdea",
            "83b4e7b3d1d045739f6a2584d7bb99c1",
            "7bb619e12f9e4ad5a07cb5b310e7caaf",
            "678cdc71be3846dca575ed73e3bb4648",
            "fca88614f06b4865b893098379209594",
            "ef84e925abc8406cbdfcbcab3733f256",
            "05dbbbe280334037b3633249a81cb541",
            "3a193a5ea7c148b0913b995dd5942507",
            "008ab01d117846a7b0d4d6770ae0d782",
            "1a5dc2464c5541dc82007ed5184778c7",
            "7e0e78ff7cee4344b832ef81e1b597dd",
            "8d16b98e415745ae944c724bc3ef1802",
            "e24f8e53122e4ae4953b35f2b9af5f64",
            "04c490b786a44ddc8e369e07a25e24a1",
            "1a5ddf98216e4cb3825e9a49938c91d0",
            "00e855c5382c40238f2003cd55bdf99b",
            "f2e7b84f171d418eb186d85f5984d741",
            "a73fc898101b43d98f1dd553d1869478",
            "8c17398414304af4bb3cf5ce0d1ea486",
            "f7c6f6fdbeb84da4905cf6b9d91d4000",
            "41e716afad0b407fa1fdb8f64dcd0623",
            "0ff12b5d06d940d399ff0e71b87e0fd9",
            "faeb514fa17c4c20bc8928717308fc79",
            "ffe892513ede45b99fbf7480ee0d824d",
            "79ad0854453a4ba5baf9aa00f46465e2",
            "02e490dd109246f8848949f0732cefb8",
            "366e2516379345f0a5054f70d4ef1aee",
            "dcfa979aa0584d00842e33f89e2d8ae0",
            "f80407e136da42388ef4bbe6bd4fbfbd",
            "1dd5d7badeaf4127ba6a3338ec8b73a5",
            "45f40d329de44a9a97dcee281ab73b64",
            "cd3afcec74cb4c0ba6dfefdd7f99a1a4",
            "9037896e71cc4868a579b885be8c82be",
            "976d88fee6134b2595fe174b90b23c12",
            "23ced7cce5f0437fa65a3b91c359cb3f",
            "aa38f758e59d4db48bc05b055b5d0d0a",
            "7a94aea71fea4692b9e8b17d7d2a105c",
            "0311eacd52614793a846746b89b66325",
            "6b805f0592824ff08a5966d7964f0b97",
            "3cccccaf180c4e5383ca10c8fb9e72f7",
            "68add9f44c334f7c9fe8a266dacb1d2a",
            "3c4d603732744520b777949c8fcbf410",
            "466095f736ee43a991e1ff5b8867a05a",
            "c1e89ef41d6146899139dd7f9563c779",
            "949a41cd73944eacab8bce0852beba54",
            "d0b6df4d9c6541299abc3ad87535e4fb",
            "b0f4ab20a178433498ea481b8c51a5e0",
            "c026104e8b3a498cb404eed6f81af15b",
            "159a5cdb3f0a4638b139b5e69a9a15cb",
            "6dde254c4fc14d6ea99a3cbc653bbd65",
            "9fe20d5bfbf74ee7ae011d067ef6d1b9",
            "54472ad52593405fa1f0db86db0a9e6b",
            "3af9b0902eb54718b8993f129d96394b",
            "3cceaf8ca8ad48caa8c7764ddbef8f65",
            "1e0aa31dbac94ae0aabad4a63f0a84de",
            "ab77e1d4fac14afbba53ebd6fb8c59bf",
            "c4f1420b80e54e328523f333e0c2f0a8",
            "f4bc8737518b4012996f43d1cd06f9a9",
            "9f7aa1e4971b48d1806fb9efa5ae51d6",
            "8683e694c0ba4efbb7a957eb7b5a07f6",
            "6de4bf74d8f84b4d84638d149949167d",
            "d09d3bad52da4239bbab83f072e3cffd",
            "978b65fe32624b29a45c00a9652b1d30",
            "defb064434974ed7951a6eb9eae2c69c",
            "03f31904b74b4094bd63124a68f3dbe7",
            "37426e6eb72744699ff1a1c87c8523d9",
            "968982567e0441d5961459d23c8e97ee"
          ]
        },
        "id": "aVPOiMmg2jj7",
        "outputId": "b50d2218-a91b-4d1c-931d-ec74782986c0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Loading model: sentence-transformers/all-MiniLM-L6-v2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "292ec25764964651a43e15f23dd247ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a7ce3711ebd476fbd4d949e50f547c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9043bdef63924fea9407d6f7183c1665"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c9c64c8047c46798b4a8907da9f9b8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44c50dfae7b748cabf72954ae67a4ffe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebe45b507f0340ff9e476a151c6fd2af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "830297a2d3874fb4bd233947364a8b92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83b4e7b3d1d045739f6a2584d7bb99c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e24f8e53122e4ae4953b35f2b9af5f64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffe892513ede45b99fbf7480ee0d824d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23ced7cce5f0437fa65a3b91c359cb3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding documents:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/242 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0b6df4d9c6541299abc3ad87535e4fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding queries:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4f1420b80e54e328523f333e0c2f0a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving top-K documents:\n",
            "Evaluating with MRR@K:\n",
            "Results for sentence-transformers/all-MiniLM-L6-v2: {1: np.float64(0.4157142857142857), 5: np.float64(0.48966666666666664), 10: np.float64(0.4993826530612245)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B3tMh4nWqWS"
      },
      "source": [
        "# **Part 3: Neural Re-Ranker (Re-ranking top 20 BM25 candidates using BERT)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxfK_XTL0_42"
      },
      "outputs": [],
      "source": [
        "# !pip install -U accelerate\n",
        "# !pip install datasets\n",
        "# !pip install -U sentence-transformers\n",
        "# !pip uninstall -y keras tensorflow tf-keras keras-nightly keras-preprocessing keras-vis\n",
        "# !pip install -U sentence-transformers --no-deps  # avoid triggering keras/tf again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzTfqjJu0_42",
        "outputId": "b38f3fe7-4ae5-4de4-9500-1882565faf59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import CrossEncoder, InputExample\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2-sgyGV0_43",
        "outputId": "39e8863d-423a-435c-c006-2c17735a7226"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1424' max='1424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1424/1424 13:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.422900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Local MRR@5 (fine-tuned CrossEncoder): 0.6352\n"
          ]
        }
      ],
      "source": [
        "# Generate training data\n",
        "train_examples = []\n",
        "for _, row in df_train_split.iterrows():\n",
        "    query = row['tweet_text']\n",
        "    gold_uid = row['cord_uid']\n",
        "\n",
        "    # Positive sample\n",
        "    pos_doc = df_collection[df_collection['cord_uid'] == gold_uid]\n",
        "    if not pos_doc.empty:\n",
        "        pos_text = (pos_doc.iloc[0]['title'] + ' ' + pos_doc.iloc[0]['abstract']).strip()\n",
        "        train_examples.append(InputExample(texts=[query, pos_text], label=1.0))\n",
        "\n",
        "    # Negative sample (BM25 top doc not equal to gold)\n",
        "    top_candidates = get_top_cord_uids(query, topk=20)\n",
        "    for neg_uid in top_candidates:\n",
        "        if neg_uid != gold_uid:\n",
        "            neg_doc = df_collection[df_collection['cord_uid'] == neg_uid]\n",
        "            if not neg_doc.empty:\n",
        "                neg_text = (neg_doc.iloc[0]['title'] + ' ' + neg_doc.iloc[0]['abstract']).strip()\n",
        "                train_examples.append(InputExample(texts=[query, neg_text], label=0.0))\n",
        "                break\n",
        "\n",
        "# Fine-tune the CrossEncoder\n",
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', num_labels=1)\n",
        "cross_encoder.fit(train_dataloader=train_dataloader, epochs=1, warmup_steps=100, output_path='./finetuned_crossencoder')\n",
        "\n",
        "# After training is done\n",
        "cross_encoder.save(\"./finetuned_crossencoder\")\n",
        "\n",
        "# Reload fine-tuned model and apply reranking\n",
        "cross_encoder = CrossEncoder('./finetuned_crossencoder')\n",
        "\n",
        "def rerank_with_cross_encoder(tweet, topk_ids):\n",
        "    candidates = df_collection[df_collection['cord_uid'].isin(topk_ids)].copy()\n",
        "    candidates['sort_idx'] = candidates['cord_uid'].apply(lambda x: topk_ids.index(x))\n",
        "    candidates = candidates.sort_values('sort_idx')\n",
        "\n",
        "    texts = (candidates['title'] + ' ' + candidates['abstract']).fillna('').tolist()\n",
        "    model_inputs = [(tweet, doc) for doc in texts]\n",
        "    scores = cross_encoder.predict(model_inputs)\n",
        "\n",
        "    return [x for _, x in sorted(zip(scores, topk_ids), reverse=True)]\n",
        "\n",
        "df_test_split['reranked_top5'] = df_test_split.apply(\n",
        "    lambda row: rerank_with_cross_encoder(row['tweet_text'], row['bm25_topk']),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "def mrr_at_k(df, pred_col, gold_col='cord_uid', k=5):\n",
        "    scores = []\n",
        "    for _, row in df.iterrows():\n",
        "        preds = row[pred_col][:k]\n",
        "        if row[gold_col] in preds:\n",
        "            rank = preds.index(row[gold_col]) + 1\n",
        "            scores.append(1 / rank)\n",
        "        else:\n",
        "            scores.append(0)\n",
        "    return np.mean(scores)\n",
        "\n",
        "mrr5 = mrr_at_k(df_test_split, pred_col='reranked_top5', k=5)\n",
        "print(f\"Local MRR@5 (fine-tuned CrossEncoder): {mrr5:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwVCcImf0_43"
      },
      "source": [
        "NEURAL RE-RANKER ON TOP OF BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW4jj5RY0_43"
      },
      "outputs": [],
      "source": [
        "NEG_PER_POS = 4     # number of negatives per positive\n",
        "CANDIDATE_K = 20    # BM25 candidate pool size\n",
        "FINAL_K     = 5     # reranked top-k\n",
        "\n",
        "train_examples = []\n",
        "for _, row in df_train_split.iterrows():\n",
        "    q       = row['tweet_text']\n",
        "    pos_uid = row['cord_uid']\n",
        "    cands = get_top_cord_uids(q, topk=NEG_PER_POS+1)\n",
        "    if pos_uid not in cands:\n",
        "        cands[-1] = pos_uid\n",
        "    for uid in cands:\n",
        "        doc_text = df_collection.loc[\n",
        "            df_collection['cord_uid']==uid, 'combined_text'\n",
        "        ].values[0]\n",
        "        label = 1.0 if uid == pos_uid else 0.0\n",
        "        train_examples.append(InputExample(texts=[q, doc_text], label=label))\n",
        "\n",
        "model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "ce = CrossEncoder(model_name, num_labels=1)\n",
        "\n",
        "train_loader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
        "ce.fit(\n",
        "    train_dataloader=train_loader,\n",
        "    epochs=2,\n",
        "    output_path=\"./checkthat_reranker\",\n",
        "    save_best_model=True\n",
        ")\n",
        "\n",
        "def neural_rerank(query, bm25_uids, topk=FINAL_K):\n",
        "    pairs = []\n",
        "    for uid in bm25_uids:\n",
        "        doc_text = df_collection.loc[\n",
        "            df_collection['cord_uid']==uid, 'combined_text'\n",
        "        ].values[0]\n",
        "        pairs.append([query, doc_text])\n",
        "    scores = ce.predict(pairs)\n",
        "    idxs = np.argsort(scores)[::-1][:topk]\n",
        "    return [bm25_uids[i] for i in idxs]\n",
        "\n",
        "df_test_split['bm25_20'] = df_test_split['tweet_text']\\\n",
        "    .apply(lambda q: get_top_cord_uids(q, topk=CANDIDATE_K))\n",
        "df_test_split['nn_top5'] = df_test_split.apply(\n",
        "    lambda r: neural_rerank(r['tweet_text'], r['bm25_20'], topk=FINAL_K),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "def mrr_list_at_5(pred_lists, true_uids):\n",
        "    rr = []\n",
        "    for preds, true in zip(pred_lists, true_uids):\n",
        "        if true in preds:\n",
        "            rr.append(1.0 / (preds.index(true) + 1))\n",
        "        else:\n",
        "            rr.append(0.0)\n",
        "    return float(np.mean(rr))\n",
        "\n",
        "nn_score = mrr_list_at_5(\n",
        "    df_test_split['nn_top5'].tolist(),\n",
        "    df_test_split['cord_uid'].tolist()\n",
        ")\n",
        "print(f'Neural re-ranking MRR@5: {nn_score:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P1Lhv4L0_43"
      },
      "source": [
        "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
        "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
        "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
        "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
        "\n",
        "BM25 MRR@5 (local split): 0.5460\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning:\n",
        "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
        "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
        "You will be able to reuse this secret in all of your notebooks.\n",
        "Please note that authentication is recommended but still optional to access public models or datasets.\n",
        "  warnings.warn(\n",
        "\n",
        "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]\n",
        "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
        "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
        "\n",
        "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]\n",
        "tokenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]\n",
        "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]\n",
        "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]\n",
        "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]\n",
        "README.md:   0%|          | 0.00/3.66k [00:00<?, ?B/s]\n",
        "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by promote_options='default'.\n",
        "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
        "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
        "  table = cls._concat_blocks(blocks, axis=0)\n",
        "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
        "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
        "\n",
        "<IPython.core.display.Javascript object>\n",
        "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
        "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
        "wandb: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
        "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
        "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
        "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
        "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33me12127030\u001b[0m (\u001b[33me12127030-tu-wien\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
        "\n",
        "Neural re-ranking MRR@5: 0.6499\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ygzzs5YeWfrv",
        "8B3tMh4nWqWS"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}